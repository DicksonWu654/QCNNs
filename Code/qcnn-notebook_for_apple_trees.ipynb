{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U tensorflow==2.3.0","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting tensorflow==2.3.0\n  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n\u001b[K     |████████████████████████████████| 320.4 MB 34 kB/s s eta 0:00:01   |█▊                              | 17.7 MB 8.7 MB/s eta 0:00:35     |██████████████████████▏         | 222.4 MB 37.4 MB/s eta 0:00:03     |██████████████████████████▊     | 267.2 MB 24.0 MB/s eta 0:00:03\n\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.12.1)\nRequirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (0.3.3)\nRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.1.2)\nRequirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (0.2.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.32.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.1.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (3.14.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.15.0)\nCollecting scipy==1.4.1\n  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n\u001b[K     |████████████████████████████████| 26.1 MB 28.5 MB/s eta 0:00:01\n\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n\u001b[K     |████████████████████████████████| 20.1 MB 51.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.6.3)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (0.36.2)\nRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (2.10.0)\nRequirement already satisfied: tensorboard<3,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (2.4.1)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (0.10.0)\nCollecting tensorflow-estimator<2.4.0,>=2.3.0\n  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n\u001b[K     |████████████████████████████████| 459 kB 48.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.0) (3.3.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (49.6.0.post20201009)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.2)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.25.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.6)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.1.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2020.12.5)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.26.2)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.7.4.3)\nInstalling collected packages: numpy, tensorflow-estimator, scipy, tensorflow\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.19.5\n    Uninstalling numpy-1.19.5:\n      Successfully uninstalled numpy-1.19.5\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.4.0\n    Uninstalling tensorflow-estimator-2.4.0:\n      Successfully uninstalled tensorflow-estimator-2.4.0\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.5.4\n    Uninstalling scipy-1.5.4:\n      Successfully uninstalled scipy-1.5.4\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.4.1\n    Uninstalling tensorflow-2.4.1:\n      Successfully uninstalled tensorflow-2.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nosmnx 1.0.1 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\nbokeh 2.2.3 requires tornado>=5.1, but you have tornado 5.0.2 which is incompatible.\nautogluon-core 0.1.0b20210219 requires numpy==1.19.5, but you have numpy 1.18.5 which is incompatible.\nautogluon-core 0.1.0b20210219 requires scipy==1.5.4, but you have scipy 1.4.1 which is incompatible.\u001b[0m\nSuccessfully installed numpy-1.18.5 scipy-1.4.1 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow-quantum","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting tensorflow-quantum\n  Downloading tensorflow_quantum-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl (5.9 MB)\n\u001b[K     |████████████████████████████████| 5.9 MB 1.2 MB/s eta 0:00:01\n\u001b[?25hCollecting cirq==0.9.1\n  Downloading cirq-0.9.1-py3-none-any.whl (1.6 MB)\n\u001b[K     |████████████████████████████████| 1.6 MB 22.2 MB/s eta 0:00:01\n\u001b[?25hCollecting sympy==1.5\n  Downloading sympy-1.5-py2.py3-none-any.whl (5.6 MB)\n\u001b[K     |████████████████████████████████| 5.6 MB 17.3 MB/s eta 0:00:01     |███████████                     | 1.9 MB 17.3 MB/s eta 0:00:01     |█████████████████████           | 3.7 MB 17.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from cirq==0.9.1->tensorflow-quantum) (1.4.1)\nRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from cirq==0.9.1->tensorflow-quantum) (1.22.4)\nRequirement already satisfied: numpy~=1.16 in /opt/conda/lib/python3.7/site-packages (from cirq==0.9.1->tensorflow-quantum) (1.18.5)\nRequirement already satisfied: networkx~=2.4 in /opt/conda/lib/python3.7/site-packages (from cirq==0.9.1->tensorflow-quantum) (2.5)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.7/site-packages (from cirq==0.9.1->tensorflow-quantum) (3.3.3)\nCollecting protobuf~=3.12.0\n  Downloading protobuf-3.12.4-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n\u001b[K     |████████████████████████████████| 1.3 MB 55 kB/s s eta 0:00:01     |████████████████████▍           | 808 kB 38.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests~=2.18 in /opt/conda/lib/python3.7/site-packages (from cirq==0.9.1->tensorflow-quantum) (2.25.1)\nCollecting freezegun~=0.3.15\n  Downloading freezegun-0.3.15-py2.py3-none-any.whl (14 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from cirq==0.9.1->tensorflow-quantum) (1.2.0)\nRequirement already satisfied: sortedcontainers~=2.0 in /opt/conda/lib/python3.7/site-packages (from cirq==0.9.1->tensorflow-quantum) (2.3.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from cirq==0.9.1->tensorflow-quantum) (3.7.4.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.7/site-packages (from sympy==1.5->tensorflow-quantum) (1.2.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from freezegun~=0.3.15->cirq==0.9.1->tensorflow-quantum) (1.15.0)\nRequirement already satisfied: python-dateutil!=2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from freezegun~=0.3.15->cirq==0.9.1->tensorflow-quantum) (2.8.1)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (2020.5)\nRequirement already satisfied: setuptools>=34.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (49.6.0.post20201009)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (1.52.0)\nRequirement already satisfied: google-auth<2.0dev,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (1.24.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (1.32.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (4.6)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (4.1.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib~=3.0->cirq==0.9.1->tensorflow-quantum) (7.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib~=3.0->cirq==0.9.1->tensorflow-quantum) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib~=3.0->cirq==0.9.1->tensorflow-quantum) (1.3.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib~=3.0->cirq==0.9.1->tensorflow-quantum) (2.4.7)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx~=2.4->cirq==0.9.1->tensorflow-quantum) (4.4.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.14.0->cirq==0.9.1->tensorflow-quantum) (0.4.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests~=2.18->cirq==0.9.1->tensorflow-quantum) (1.26.2)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests~=2.18->cirq==0.9.1->tensorflow-quantum) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests~=2.18->cirq==0.9.1->tensorflow-quantum) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests~=2.18->cirq==0.9.1->tensorflow-quantum) (2.10)\nInstalling collected packages: protobuf, sympy, freezegun, cirq, tensorflow-quantum\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.14.0\n    Uninstalling protobuf-3.14.0:\n      Successfully uninstalled protobuf-3.14.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.7.1\n    Uninstalling sympy-1.7.1:\n      Successfully uninstalled sympy-1.7.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nortools 8.1.8487 requires absl-py>=0.11, but you have absl-py 0.10.0 which is incompatible.\nortools 8.1.8487 requires protobuf>=3.14.0, but you have protobuf 3.12.4 which is incompatible.\u001b[0m\nSuccessfully installed cirq-0.9.1 freezegun-0.3.15 protobuf-3.12.4 sympy-1.5 tensorflow-quantum-0.4.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing tensorflow\nimport tensorflow as tf\nimport tensorflow_quantum as tfq\n\nfrom tensorflow.keras import datasets, layers, models\n\n#Importing some tensorflow quantum stuff\nimport cirq\nimport sympy\n\n#For data manipulation\nimport numpy as np\n\nimport collections\n\n#to plot stuff\nimport matplotlib.pyplot as plt","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array, smart_resize\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.preprocessing import image","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\nclass_name = df['labels'].value_counts().index\ndf['labels'] = df['labels'].astype('category')\ndf['label_num'] = df['labels'].cat.codes","execution_count":128,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = (90, 90)\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./225,\n                                                                validation_split=0.4)\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)","execution_count":177,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/plant-pathology-2021-fgvc8/train_images'","execution_count":178,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_dataframe(dataframe=df,\n                                                    directory=train_dir,\n                                                    subset='training',\n                                                    x_col=\"image\",\n                                                    y_col=\"label_num\",\n                                                    shuffle=True,\n                                                    color_mode=\"grayscale\",\n                                                    target_size=IMAGE_SIZE,\n                                                    batch_size=11180,\n                                                    class_mode='raw')\n\n# val_generator = train_datagen.flow_from_dataframe(dataframe=df,\n#                                                     directory=train_dir,\n#                                                     subset=\"validation\",\n#                                                     x_col=\"image\",\n#                                                     y_col=\"label_num\",\n#                                                     shuffle=True,\n#                                                     color_mode=\"grayscale\",\n#                                                     target_size=IMAGE_SIZE,\n#                                                     batch_size=10,\n#                                                     class_mode='raw')","execution_count":179,"outputs":[{"output_type":"stream","text":"Found 11180 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for n,x in enumerate(train_generator):\n#     print(type(x[0]), type(x[1]))\n#     break","execution_count":180,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-180-568e6b0cf775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# convert it to an 8-bit grayscale image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I;16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rgba'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \"\"\"\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train_generator[0][0]\ntrain_y = train_generator[0][1]","execution_count":181,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_x = np.ndarray((11180, 150, 150,1))\n# train_y = np.ndarray((11180))","execution_count":145,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for x in train_generator:\n#     np.append(train_x, x[0])\n#     np.append(train_y, x[1])\n#     break","execution_count":152,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_y","execution_count":153,"outputs":[{"output_type":"execute_result","execution_count":153,"data":{"text/plain":"array([6.90839482e-310, 6.90839482e-310, 4.67986397e-310, ...,\n       8.09028184e-003, 4.75694704e-003, 5.31250331e-003])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_x.shape,train_y.shape","execution_count":154,"outputs":[{"output_type":"execute_result","execution_count":154,"data":{"text/plain":"((11180, 150, 150, 1), (11180,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining the whole thing!!!\nclass QConv(tf.keras.layers.Layer):\n  #initializaiton of the QCNN layer\n  def __init__(self, filter_size, depth, activation = None, name = None, kernel_regularizer=None, **kwangs):\n    #Standard notation thingy\n    super(QConv, self).__init__(name=name, **kwangs)\n\n    #Defining of the varaibles\n    self.filter_size = filter_size\n    self.depth = depth\n    self.learning_params = []\n    self.QCNN_layer_gen()\n    self.activation = tf.keras.layers.Activation(activation)\n    self.kernel_regularizer = kernel_regularizer\n  \n  #Initialize parameters for the quantum gates\n  def _get_new_param(self):\n    #Literally just generates a string \"p0\"... Instead of 0 it's just a number that\n    new_param = sympy.symbols('p'+str(len(self.learning_params)))\n    #Increase the size of the list (thus the numbers keep increasing (so there's no duplicates))\n    self.learning_params.append(new_param)\n    return new_param\n  \n  #This just defines 2 parameterized qubit gates and places them\n  def _QConv(self, step, target, qubits):\n    #First defining a Z and an X gate. First part = the rotation value (where we place our parameter), second part = where we place our gates\n    yield cirq.CZPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n    yield cirq.CXPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n  \n  def QCNN_layer_gen(self):\n    #Pixels = the area which the filter will cover\n    pixels = self.filter_size**2\n\n    #So we're going to take our kernal and map it to qubits\n    cirq_qubits = cirq.GridQubit.rect(self.filter_size, self.filter_size)\n\n    #How you define the start of a quantum circuit\n    input_circuit = cirq.Circuit()\n\n    #There's another set of parameterized gates here. And we've got to define it's parameters\n    input_params = [sympy.symbols('a%d' %i) for i in range(pixels)]\n\n    #Now we apply those initial RX gates at the beginning for each qubit\n    for i, qubit in enumerate(cirq_qubits):\n      input_circuit.append(cirq.rx(np.pi*input_params[i])(qubit))\n    \n    #We're going to start antoher part, this time it's the kernal part\n    QCNN_circuit = cirq.Circuit()\n\n    #Basically something to help with the architechture of the kernal part (to help with the placement of the X and Z gates)\n    step_size = [2**i for i in range(np.log2(pixels).astype(np.int32))]\n    \n    #This is the appending of said X and Z gates\n    for step in step_size:\n      for target in range(0, pixels, 2*step):\n        QCNN_circuit.append(self._QConv(step,target,cirq_qubits))\n    \n    #now take the 2 parts of the quantum circuit to merge them all together\n    full_circuit = cirq.Circuit()\n    full_circuit.append(input_circuit)\n    full_circuit.append(QCNN_circuit)\n\n    #save it to use it later\n    self.circuit = full_circuit\n\n    #Save the parameters to use later\n    self.params = input_params + self.learning_params\n\n    #Save the operators (for the output) for later use\n    self.op = cirq.Z(cirq_qubits[0])\n  \n  #Intializes everything... It creates the layer (with weights and stuff)\n  def build(self, input_shape):\n    #What's the input (image) width? Height? Number of channels?\n    self.width = input_shape[1]\n    self.height = input_shape[2]\n    self.channel = input_shape[3]\n\n    # The number of times which the kernal will pass on the image\n    self.num_x = self.width - self.filter_size + 1\n    self.num_y = self.height - self.filter_size + 1\n\n    #Initializing the kernal! name, (how many (if there are 8, then it'll be a rectangular prism, but ostensibly 8 different kernals), channels, number of parameters each)\n    #Then we initialzie the parameters, plus slap on a regularator if we wanted to\n    self.kernel = self.add_weight(name = 'kernal',\n                                 shape = [self.depth, self.channel, len(self.learning_params)],\n                                 initializer = tf.keras.initializers.glorot_normal(),\n                                 regularizer = self.kernel_regularizer)\n    \n    #We take our thing and convert it to a (quantum?) tensor\n    self.circuit_tensor = tfq.convert_to_tensor([self.circuit] * self.num_x * self.num_y * self.channel)\n  \n  #Where the computation happens\n  def call(self, inputs):\n    #This is generating a giant stack of all the segements of the inputs which we're going to pass over the kernal\n    #Also: It's just adding the slice to the whole stack each time. (It works like. Which cord on the map, then take a bit out of that with the size) \n    stack_set = None\n    for i in range(self.num_x):\n      for j in range(self.num_y):\n        slice_part = tf.slice(inputs, [0, i, j, 0], [-1, self.filter_size, self.filter_size, -1])\n        slice_part = tf.reshape(slice_part, shape=[-1, 1, self.filter_size, self.filter_size, self.channel])\n        if stack_set == None:\n          stack_set = slice_part\n        else:\n          stack_set = tf.concat([stack_set, slice_part], 1)\n    #Then we just reformat it\n    stack_set = tf.transpose(stack_set, perm=[0, 1, 4, 2, 3])\n    stack_set = tf.reshape(stack_set, shape=[-1, self.filter_size**2])\n\n    #Kind of reformats (except with some duplication) the (quantum?) tensor into a usable form\n    circuit_inputs = tf.tile([self.circuit_tensor], [tf.shape(inputs)[0], 1])\n    circuit_inputs = tf.reshape(circuit_inputs, shape=[-1])\n    tf.fill([tf.shape(inputs)[0]*self.num_x*self.num_y, 1], 1)\n    \n    #Gonna take our inputs (now in the form of the stack) and pass them through our kernals\n    outputs = []\n    for i in range(self.depth):\n      #Now we call the kernals we defined in build\n      controller = tf.tile(self.kernel[i], [tf.shape(inputs)[0]*self.num_x*self.num_y, 1])\n      #Actually passing into the QCNN layer\n      outputs.append(self.single_depth_QCNN(stack_set, controller, circuit_inputs))\n    #reformating\n    output_tensor = tf.stack(outputs, axis=3)\n    output_tensor = tf.math.acos(tf.clip_by_value(output_tensor, -1+1e-5, 1-1e-5)) / np.pi\n    \n    #Take our output, shove it through the activation, and then return it\n    return self.activation(output_tensor)\n  \n  def single_depth_QCNN(self, input_data, controller, circuit_inputs):\n    #Shove it on GPU\n    with tf.device('/device:GPU:0'):\n      #Reformat the input data\n      input_data = tf.concat([input_data, controller],1)\n      #Then taking our input and shoving it through the QCNN (along with it's paramters)\n      QCNN_output = tfq.layers.Expectation()(circuit_inputs,\n                                            symbol_names = self.params,\n                                            symbol_values = input_data,\n                                            operators = self.op)\n      #Reformat x 2\n      QCNN_output = tf.reshape(QCNN_output, shape=[-1, self.num_x, self.num_y, self.channel])\n      return tf.math.reduce_sum(QCNN_output, 3)","execution_count":182,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining the varaibles to intitalize the QCNN\nwidth = 90\nheight = 90","execution_count":183,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initializing the model\nqcnn_model = models.Sequential()\n#The QCNN!!!!!\nqcnn_model.add(QConv(filter_size=2, depth=4, activation='relu', \n                     name='qconv1', input_shape=(width, height, 1)))\n#So we can pase it to linear layers\nqcnn_model.add(layers.Flatten())\nqcnn_model.add(layers.Dense(32, activation='relu'))\n#Important to have a softmax here... So all the probabilities add up to 100%\nqcnn_model.add(layers.Dense(12, activation='softmax'))","execution_count":184,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qcnn_model.summary()","execution_count":185,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nqconv1 (QConv)               (None, 89, 89, 4)         24        \n_________________________________________________________________\nflatten (Flatten)            (None, 31684)             0         \n_________________________________________________________________\ndense (Dense)                (None, 32)                1013920   \n_________________________________________________________________\ndense_1 (Dense)              (None, 12)                396       \n=================================================================\nTotal params: 1,014,340\nTrainable params: 1,014,340\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"qcnn_model.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":186,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qcnn_history = qcnn_model.fit(train_x, train_y, steps_per_epoch=500,\n                        epochs=10, batch_size=5)","execution_count":191,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n","name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"Creating variables on a non-first call to a function decorated with tf.function.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-191-040d180bc749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m qcnn_history = qcnn_model.fit(train_x, train_y, steps_per_epoch=500,\n\u001b[0;32m----> 2\u001b[0;31m                         epochs=10, batch_size=5)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    814\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         raise ValueError(\"Creating variables on a non-first call to a function\"\n\u001b[0m\u001b[1;32m    817\u001b[0m                          \" decorated with tf.function.\")\n\u001b[1;32m    818\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y.shape, train_x.shape","execution_count":193,"outputs":[{"output_type":"execute_result","execution_count":193,"data":{"text/plain":"((11180,), (11180, 90, 90, 1))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.config.run_functions_eagerly(True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}